{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#molby dick wordSet\n",
    "molbyWordSet = nltk.corpus.gutenberg.words('melville-moby_dick.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first 22 times\n",
    "molbyWord22 = molbyWordSet[:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Late',\n",
       " 'Consumptive',\n",
       " 'Usher',\n",
       " 'to',\n",
       " 'a',\n",
       " 'Grammar',\n",
       " 'School',\n",
       " ')']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molbyWord22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moby\n",
      "Dick\n",
      "by\n",
      "Herman\n",
      "Melville\n",
      "ETYMOLOGY\n",
      "Supplied\n",
      "by\n",
      "a\n",
      "Late\n",
      "Consumptive\n",
      "Usher\n",
      "to\n",
      "a\n",
      "Grammar\n",
      "School\n"
     ]
    }
   ],
   "source": [
    "#cleaning of data keeping only words and removing '[' , ')', '.', '1851'\n",
    "#isalpha() gives true if the word is comprised of word\n",
    "#and gives false if the word is comprised of date or puntucation\n",
    "for word in molbyWord22:\n",
    "    if word.isalpha():\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "moby\n",
      "dick\n",
      "by\n",
      "herman\n",
      "melville\n",
      "1851\n",
      "]\n",
      "etymology\n",
      ".\n",
      "(\n",
      "supplied\n",
      "by\n",
      "a\n",
      "late\n",
      "consumptive\n",
      "usher\n",
      "to\n",
      "a\n",
      "grammar\n",
      "school\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#makes all our word same case(usually lowercase)\n",
    "for word in molbyWord22:\n",
    "    print(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalizing\n",
    "norm = [word for word in molbyWord22 if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lowercase\n",
    "lowercaseNorm = [word.lower() for word in norm ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moby',\n",
       " 'dick',\n",
       " 'by',\n",
       " 'herman',\n",
       " 'melville',\n",
       " 'etymology',\n",
       " 'supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'late',\n",
       " 'consumptive',\n",
       " 'usher',\n",
       " 'to',\n",
       " 'a',\n",
       " 'grammar',\n",
       " 'school']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowercaseNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "stemmer helps to further normalize the text like removing affixes\n",
    "stemmer helps to find the root word. There are various stemmer\n",
    "'''\n",
    "\n",
    "#potter Stemmer\n",
    "list   = [\"cat\", \"cats\", \"lie\", \"lied\", \"lying\", \"run\", \"ran\", \"running\", \"running away\", \"month\", \"monthly\", 'city', \"cities\", \"woman\",\"woman\"]\n",
    "porter = nltk.PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "cat\n",
      "lie\n",
      "lie\n",
      "lie\n",
      "run\n",
      "ran\n",
      "run\n",
      "running away\n",
      "month\n",
      "monthli\n",
      "citi\n",
      "citi\n",
      "woman\n",
      "woman\n"
     ]
    }
   ],
   "source": [
    "for word in list:\n",
    "    print(porter.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lancaster stemmer\n",
    "lancaster = nltk.LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "cat\n",
      "lie\n",
      "lied\n",
      "lying\n",
      "run\n",
      "ran\n",
      "run\n",
      "running away\n",
      "mon\n",
      "month\n",
      "city\n",
      "city\n",
      "wom\n",
      "wom\n"
     ]
    }
   ],
   "source": [
    "for word in list:\n",
    "    print(lancaster.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lemmatizer\n",
    "#uses word net resources provided by nltk\n",
    "#intesive process takes lot time compared to other stemmer.so, maynot be suitable for many purpose\n",
    "wnlem = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "cat\n",
      "lie\n",
      "lied\n",
      "lying\n",
      "run\n",
      "ran\n",
      "running\n",
      "running away\n",
      "month\n",
      "monthly\n",
      "city\n",
      "city\n",
      "woman\n",
      "woman\n"
     ]
    }
   ],
   "source": [
    "for word in list:\n",
    "    print(wnlem.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
